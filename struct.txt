1) git clone the repo
2) cd into the repo
3) preform pre-pip install steps (see requirements.txt)
4) follow struct.txt to complete installation steps
5) cd to main and rename .env.dev to .env - fill out everything you are able to

```bash
________struxt.txt
# <!---- python & nvidia for WSL2---->
sudo apt-get install python3-dev default-libmysqlclient-dev build-essential -y
apt-get remove torch torchvision torchaudio cudatoolkit=11.1 -y
# get a copy of micromamba, miniconda, or anaconda
conda update conda && conda install pip
py -m pip install --upgrade pip
py -m pip install --upgrade setuptools
py -m pip install --upgrade wheel
py -m pip install --upgrade pipenv
py -m pip install --upgrade poetry
conda install -c conda-forge torch torchvision torchaudio
py -m pip install nvidia-pyindex --extra-index-url https://pypi.ngc.nvidia.com
py -m pip install nvidia-cuda-runtime-cu12
sudo apt-get install nvidia-cuda-toolkit -y && sudo apt-get install nvim -y

________
!#bin/bash
py -m pip install nvidia-pyindex --extra-index-url https://pypi.ngc.nvidia.com
py -m pip install nvidia-cuda-runtime-cu12
https://docs.djangoproject.com/en/4.1/topics/
sudo apt-get install python3-dev default-libmysqlclient-dev build-essential
________
!#bin/bash
# django init
django-admin startproject cognshell
cd cognshell
py manage.py runserver # port number 8000 by default
py manage.py startapp cognsh
mkdir templates && cd templates && echo loremipsum > index.html

________
cd textgen-webui
--loader exllama


________<!--- best to install the following manually before doing pip install -r --->
pip install langsmith && conda install langchain -c conda-forge
django[all]
mysqlclient
mariadb[all
mod-wsgi 
mod_ssl
mod_rewrite
mod_deflate
xonsh
```
________<!--- misc. structs incl. docker and cli args + web-links --->
llama.cpp
I believe you need to add `-ngl N, --n-gpu-layers` argument
`N_GPU_LAYERS`


________
localai / ialacol
```*args(example)
replicas: 1
deployment:
  image: quay.io/chenhunghan/ialacol-cuda12:latest
  env:
    DEFAULT_MODEL_HG_REPO_ID: TheBloke/Starcoderplus-Guanaco-GPT4-15B-V1.0-GGML
    DEFAULT_MODEL_FILE: starcoderplus-guanaco-gpt4.ggmlv1.q4_0.bin
    GPU_LAYERS: 40
resources:
  {}
model:
  persistence:
    size: 20Gi
    accessModes:
      - ReadWriteOnce
    storageClassName: ~
service:
  type: ClusterIP
  port: 8000
  annotations: {}
nodeSelector: {}
tolerations: []
affinity: {}
```

________known models
- [LLaMa 2 variants](https://huggingface.co/meta-llama)
- [OpenLLaMA variants](https://github.com/openlm-research/open_llama)
- [StarCoder variants](https://huggingface.co/bigcode/starcoder)
- [WizardCoder](https://huggingface.co/WizardLM/WizardCoder-15B-V1.0)
- [StarChat variants](https://huggingface.co/HuggingFaceH4/starchat-beta)
- [MPT-7B](https://www.mosaicml.com/blog/mpt-7b)
- [MPT-30B](https://huggingface.co/mosaicml/mpt-30b)
- [Falcon](https://falconllm.tii.ae/)

________
swagger + openAPI
https://swagger.io/docs/specification/about/
https://editor.swagger.io/

________
https://github.com/browserless/chrome
docker run -p 3000:3000 browserless/chrome
Visit http://localhost:3000/ to use the interactive debugger.

________

